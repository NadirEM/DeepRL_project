{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "drl_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHMQ6kLPF9p-",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5_sA57F9qB",
        "colab_type": "code",
        "outputId": "18b67335-4135-4c51-944d-251e66fa5d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "!pip install scikit-video # added\n",
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwO2XH6QF9qF",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5KGoFgeF9qH",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW9NgwNXF9qI",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivq0cqz_F9qK",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0pL2imBF9qL",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jH7pXZzF9qN",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0osACOJRF9qO",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thxdoAeAF9qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmI4QoFHF9qS",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L7XDHGHF9qT",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAimDR2XF9qU",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCXXWdTjF9qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRQELGLoF9qZ",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-5Uk6LFF9qb",
        "colab_type": "text"
      },
      "source": [
        "The function act is used to return the action to do according to a state as input and a probability parameterized by epsilon. The value of epsilon is essential in the trade-off Exploration-Exploitation. A high value will favour exploration i.e. explore the actions in order to learn about them and improves the chances of the agent of getting future reward. A small value will favour exploitation i.e. the agent uses what it has already learned to maximize its total reward. The agent exploits by taking the actions it expects to provide the largest rewards.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKGq9CI1F9qb",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLy6UTjJF9qc",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4PByPiIF9qe",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5378sKeuF9qf",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaPuJXLxF9qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256 \n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        # self.position[-2:, :] = -1 # rather self.position[:,-2:]\n",
        "        self.position[:,-2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0: # right\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1: # left\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2: # down\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3: # up\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        # self.position[-2:, :] = -1 # rather self.position[:,-2:] \n",
        "        self.position[:,-2:] = -1\n",
        "\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssye-iU0F9ql",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSdrsSm9F9qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=21 # set small when debugging\n",
        "epochs_test=11 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIZGonxzF9qt",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsTtOpjZF9qu",
        "colab_type": "text"
      },
      "source": [
        "The array `board` contains the rewards of each cell (0, +0.5 or -1), each cell visited by the rat changes the reward to 0.\n",
        "`position` has 0 in all cells except the one the rat is in (with value 1) and the boarders (2 first lines and columns, 2 last lines and columns) with value -1. These two arrays are used in the states of the model by concatenation of the values for each of the cells in the visibility of the rat (5^2 cells)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBt4Gh3-F9qu",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3CyPExUF9qv",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgnCf6rMF9qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(0, self.n_action, size=1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvOY4mbgF9qz",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrtfLOMwF9qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "\n",
        "        game_over = False\n",
        "    \n",
        "        win = 0\n",
        "        lose = 0\n",
        "    \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbBvMptBF9q2",
        "colab_type": "code",
        "outputId": "e690500f-7fde-4163-804c-0cfcc48240c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.5/13.0. Average score (-1.5)\n",
            "Win/lose count 10.5/14.0. Average score (-2.5)\n",
            "Win/lose count 12.0/19.0. Average score (-4.0)\n",
            "Win/lose count 9.5/11.0. Average score (-3.375)\n",
            "Win/lose count 8.0/12.0. Average score (-3.5)\n",
            "Win/lose count 13.5/10.0. Average score (-2.3333333333333335)\n",
            "Win/lose count 4.0/15.0. Average score (-3.5714285714285716)\n",
            "Win/lose count 8.0/14.0. Average score (-3.875)\n",
            "Win/lose count 9.0/10.0. Average score (-3.5555555555555554)\n",
            "Win/lose count 14.5/18.0. Average score (-3.55)\n",
            "Win/lose count 6.5/11.0. Average score (-3.6363636363636362)\n",
            "Final score: -3.6363636363636362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ICrFoWF9q5",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfZRTwYJF9q6",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIcaWBnqLvgB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLbLDX1F9q7",
        "colab_type": "text"
      },
      "source": [
        "1) Let's prove that  \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')}[r(s,a,s')+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "We have: \n",
        "\n",
        "\\begin{align*}\n",
        "Q^{\\pi}(s,a) &= E_{p^{\\pi}} [\\sum_{t\\geq0} \\gamma^t r(s_t, a_t) | s_0=s, a_0=a] \\\\\n",
        "&= r(s,a) + E_{p^{\\pi}} [\\sum_{t\\geq1} \\gamma^t r(s_t, a_t) | s_0=s, a_0=a] \\\\\n",
        "&= r(s,a) + E_{(s',a')}[\\gamma E_{p^{\\pi}}[\\sum_{t\\geq1} \\gamma^{t-1} r(s_t, a_t) | s_1=s', a_1=a']] \\\\\n",
        "&= r(s,a) + E_{(s',a')}[\\gamma E_{p^{\\pi}}[\\sum_{t\\geq0} \\gamma^{t} r(s_t, a_t) | s_0=s', a_0=a']] \\\\\n",
        "&= r(s,a) + E_{(s',a')}[\\gamma Q^{\\pi}(s',a')] \\\\\n",
        "&= E_{(s',a')}[r(s,a,s')+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "2) Let $\\pi^*$ be the optimal policy. We want to prove that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'}[r(s,a,s')+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "\n",
        "We have: \n",
        "\n",
        "\\begin{align*}\n",
        "Q^{*}(s,a)&= \\max_{\\pi} Q^{\\pi}(s,a)  \\\\\n",
        "&= \\max_{\\pi} E_{(s',a')}[r(s,a,s')+\\gamma Q^{\\pi}(s',a')]\\\\\n",
        "&= \\max_{\\pi} (r(s,a) + E_{(s',a')}[\\gamma Q^{\\pi}(s',a')])\\\\\n",
        "&= \\max_{\\pi} (r(s,a) + E_{s'}[\\gamma \\max_{a'}Q^{\\pi}(s',a')])\\\\\n",
        "&= r(s,a) + E_{s'}[\\gamma \\max_{\\pi, a'} Q^{\\pi}(s',a')]\\\\\n",
        "&= r(s,a) + E_{s'}[\\gamma  \\max_{a'} Q^{*}(s',a')]\\\\\n",
        "&= E_{s'}[r(s,a,s')+\\gamma\\max_{a'}Q^{*}(s',a')]\n",
        "\\end{align*}\n",
        "\n",
        "3) The idea is to train a deep network $Q(s,a,\\theta)$ of paramater $\\theta$ to predict $Q^{*}(s,a)$ given observation $s$ and action $a$.\n",
        "As we are in the context of a regression problem and we want to minimize the distance between the output of the network and $Q^{*}(s,a)$, one could use the loss function: \n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s'}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*} \n",
        "\n",
        "using the result of the previous question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZc-Xv6F9q8",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OhsE2QUF9q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "      if len(self.memory) < self.max_memory: # the maximum memory size is not reached thus the new move can be appended to the list\n",
        "        self.memory.append(m)\n",
        "      else:\n",
        "        self.memory.pop(0) # the maximum memory size is reached thus one move (the first one) needs to be removed\n",
        "        self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(low=0, high=len(self.memory))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md1u9rMoF9rA",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGiXD6CrF9rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNdfb_vWF9rE",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQiMnLFEF9rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s.reshape(1,-1)))\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            ######## FILL IN\n",
        "            states = self.memory.random_access()\n",
        "            input_states[i] = states[0]\n",
        "            next_state = states[1]\n",
        "            action = states[2]\n",
        "            reward = states[3]\n",
        "            game_over_= states[4]\n",
        "            \n",
        "            target_q[i] = self.model.predict(input_states[i].reshape(1,-1))[0]\n",
        "            if game_over_:\n",
        "                ######## FILL IN\n",
        "                target_q[i][action] = reward\n",
        "            else:\n",
        "                ######## FILL IN\n",
        "                target_q[i][action] = reward + self.discount * np.max(self.model.predict(next_state.reshape(1,-1)))\n",
        "\n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states.reshape(self.batch_size, 25*self.n_state), target_q)\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)favoured\n",
        "        # model.compile(\"sgd\", \"mse\")\n",
        "        model.compile(\"adam\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        ####### FILL IN\n",
        "        model = Sequential()\n",
        "        model.add(Dense(50, activation='relu'))\n",
        "        model.add(Dense(30, activation='relu'))\n",
        "        model.add(Dense(30, activation='relu'))\n",
        "        model.add(Dense(self.n_action, activation='linear'))\n",
        "        \n",
        "        # model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\") # test adam\n",
        "        model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpIdqv3FF9rJ",
        "colab_type": "code",
        "outputId": "920b0b38-2e0a-4b8d-fc09-098b76bd2090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 128) # lr=0.1, memory_size=2000, bs = 32\n",
        "train(agent, env, epochs_train, prefix='fc_train') # time execution : 19 minutes\n",
        "HTML(display_videos('fc_train10.mp4')) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/021 | Loss 0.0008 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 001/021 | Loss 0.0290 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 002/021 | Loss 0.0036 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 003/021 | Loss 0.0130 | Win/lose count 4.0/0 (4.0)\n",
            "Epoch 004/021 | Loss 0.0065 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 005/021 | Loss 0.0023 | Win/lose count 8.5/5.0 (3.5)\n",
            "Epoch 006/021 | Loss 0.0020 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 007/021 | Loss 0.0015 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 008/021 | Loss 0.0085 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 009/021 | Loss 0.0033 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 010/021 | Loss 0.0044 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 011/021 | Loss 0.0022 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 012/021 | Loss 0.0024 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 013/021 | Loss 0.0141 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 014/021 | Loss 0.0020 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 015/021 | Loss 0.0107 | Win/lose count 12.5/5.0 (7.5)\n",
            "Epoch 016/021 | Loss 0.0138 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 017/021 | Loss 0.0257 | Win/lose count 12.5/3.0 (9.5)\n",
            "Epoch 018/021 | Loss 0.0019 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 019/021 | Loss 0.0018 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 020/021 | Loss 0.0039 | Win/lose count 7.0/4.0 (3.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKyWshsOF9rO",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dUzUuMBF9rR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        ###### FILL IN\n",
        "        model = Sequential()\n",
        "        model.add(Reshape(target_shape=(5,5,self.n_state)))\n",
        "        model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "        model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(self.n_action, activation='linear'))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        # model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlVj0BvzF9rV",
        "colab_type": "code",
        "outputId": "5c17e2fd-1c27-4721-918d-f4c78371b2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train') # time execution : 7 minutes\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/021 | Loss 0.0021 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 001/021 | Loss 0.0025 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 002/021 | Loss 0.0034 | Win/lose count 2.5/1.0 (1.5)\n",
            "Epoch 003/021 | Loss 0.0007 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 004/021 | Loss 0.0623 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 005/021 | Loss 0.0072 | Win/lose count 2.5/5.0 (-2.5)\n",
            "Epoch 006/021 | Loss 0.0015 | Win/lose count 2.5/7.0 (-4.5)\n",
            "Epoch 007/021 | Loss 0.0007 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 008/021 | Loss 0.0027 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 009/021 | Loss 0.0034 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 010/021 | Loss 0.0047 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 011/021 | Loss 0.0009 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 012/021 | Loss 0.0036 | Win/lose count 10.0/7.0 (3.0)\n",
            "Epoch 013/021 | Loss 0.0108 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 014/021 | Loss 0.0040 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 015/021 | Loss 0.0579 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 016/021 | Loss 0.0021 | Win/lose count 6.5/0 (6.5)\n",
            "Epoch 017/021 | Loss 0.0605 | Win/lose count 11.5/0 (11.5)\n",
            "Epoch 018/021 | Loss 0.0116 | Win/lose count 16.0/2.0 (14.0)\n",
            "Epoch 019/021 | Loss 0.0018 | Win/lose count 9.5/3.0 (6.5)\n",
            "Epoch 020/021 | Loss 0.0025 | Win/lose count 3.5/0 (3.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWzBWhMEF9rY",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgsvIS7F9rZ",
        "colab_type": "code",
        "outputId": "866735f2-5f1a-462f-cfe4-083c00c7fe7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3) \n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32) \n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 128)# changed bs from 32 to 128\n",
        "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json') # changed agent_cnn to agent_fc\n",
        "# agent_cnn.load(name_weights='fc_trainmodel.h5', name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 11.5/1.0. Average score (10.5)\n",
            "Win/lose count 3.5/0. Average score (7.0)\n",
            "Win/lose count 4.0/2.0. Average score (5.333333333333333)\n",
            "Win/lose count 8.0/3.0. Average score (5.25)\n",
            "Win/lose count 5.5/0. Average score (5.3)\n",
            "Win/lose count 11.0/1.0. Average score (6.083333333333333)\n",
            "Win/lose count 7.0/2.0. Average score (5.928571428571429)\n",
            "Win/lose count 3.5/2.0. Average score (5.375)\n",
            "Win/lose count 8.0/3.0. Average score (5.333333333333333)\n",
            "Win/lose count 12.0/2.0. Average score (5.8)\n",
            "Win/lose count 8.0/4.0. Average score (5.636363636363637)\n",
            "Final score: 5.636363636363637\n",
            "Test of the FC\n",
            "Win/lose count 6.5/0. Average score (6.5)\n",
            "Win/lose count 9.0/1.0. Average score (7.25)\n",
            "Win/lose count 9.0/4.0. Average score (6.5)\n",
            "Win/lose count 7.5/3.0. Average score (6.0)\n",
            "Win/lose count 2.5/2.0. Average score (4.9)\n",
            "Win/lose count 4.5/0. Average score (4.833333333333333)\n",
            "Win/lose count 7.0/2.0. Average score (4.857142857142857)\n",
            "Win/lose count 8.0/3.0. Average score (4.875)\n",
            "Win/lose count 7.0/4.0. Average score (4.666666666666667)\n",
            "Win/lose count 3.0/1.0. Average score (4.4)\n",
            "Win/lose count 11.0/7.0. Average score (4.363636363636363)\n",
            "Final score: 4.363636363636363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGqbXRIMF9rg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "d0d66a0f-f52a-4af3-d042-66234a388343"
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unetr23bF9rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "8f990038-8bf0-4361-8704-a237b4e512fd"
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8etTdyzmF9rj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "By looking at the following results (20 epochs for training, 10 for test), one can observe that the CNN works better for all the different temperature values. A higher temperature implies a better performance because when the temperature is high, there are more cheese in the grid and less poisonous cells (malus[bonus>0]=0 in the Environment class). One issue that can be observed is the lack of exploration.\n",
        "\n",
        "\n",
        "temperature=0.1:\n",
        "\n",
        "DQN training algorithm using a CNN: 2.86\n",
        "\n",
        "DQN training algorithm using a cascade of FC layers: 1.18\n",
        "\n",
        "\n",
        "temperature=0.3:\n",
        "\n",
        "DQN training algorithm using a CNN: 5.64\n",
        "\n",
        "DQN training algorithm using a cascade of FC layers: 4.37\n",
        "\n",
        "\n",
        "temperature=0.5:\n",
        "\n",
        "DQN training algorithm using a CNN: 17.0\n",
        "\n",
        "DQN training algorithm using a cascade of FC layers: 6.91\n",
        "\n",
        "\n",
        "temperature=0.7:\n",
        "\n",
        "DQN training algorithm using a CNN: 23.91\n",
        "\n",
        "DQN training algorithm using a cascade of FC layers: 8.91\n",
        "\n",
        "\n",
        "temperature=0.9:\n",
        "\n",
        "DQN training algorithm using a CNN: 39.82\n",
        "\n",
        "DQN training algorithm using a cascade of FC layers: 13.82\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhTblfI5F9rk",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRa3zNrvF9rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "\n",
        "    for e in range(epoch): # 40 epochs\n",
        "        # decreasing epsilon-greedy exploration\n",
        "        eps = 1 - e*0.1\n",
        "        if e < 10: # 1 to 0.1 with a 0.1 step until epoch 10, then 0.1\n",
        "          agent.set_epsilon(eps)\n",
        "        else:\n",
        "          agent.set_epsilon(0.1)\n",
        "\n",
        "\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "\n",
        "\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256 \n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        self.position[-2:, :] = -1\n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action, train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        # self.position[-2:, :] = -1 # rather self.position[:,-2:]\n",
        "        self.position[:,-2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0: # right\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1: # left\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2: # down\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3: # up\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "\n",
        "        # reward = self.board[self.x, self.y]\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        # self.position[-2:, :] = -1 # rather self.position[:,-2:]\n",
        "        self.position[:, -2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "        \n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n",
        "\n",
        "\n",
        "\n",
        "## use those samples of code:\n",
        "#In train explore:\n",
        "# state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "## In Environment exploring:\n",
        "# You will have to change n_state to 3 because you will use one more layer!\n",
        "# reward = 0\n",
        "# if train:\n",
        "#     reward = -self.malus_position[self.x, self.y]\n",
        "# self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "# reward = reward + self.board[self.x, self.y]\n",
        "# # 3 \"feature\" states instead of 2\n",
        "# state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "#                                 self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "#                         self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxECkDbPF9rm",
        "colab_type": "code",
        "outputId": "c745c6df-6856-4389-9845-a37e4f2b95cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, 41, prefix='cnn_train_explore') # time execution : \n",
        "HTML(display_videos('cnn_train_explore40.mp4'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/041 | Loss 0.0124 | Win/lose count 12.0/25.50000000000002 (-13.500000000000021)\n",
            "Epoch 001/041 | Loss 0.0046 | Win/lose count 9.5/28.000000000000078 (-18.500000000000078)\n",
            "Epoch 002/041 | Loss 0.0069 | Win/lose count 5.5/20.200000000000028 (-14.700000000000028)\n",
            "Epoch 003/041 | Loss 0.0075 | Win/lose count 9.0/25.400000000000052 (-16.400000000000052)\n",
            "Epoch 004/041 | Loss 0.0079 | Win/lose count 15.0/24.900000000000013 (-9.900000000000013)\n",
            "Epoch 005/041 | Loss 0.0064 | Win/lose count 13.0/21.300000000000058 (-8.300000000000058)\n",
            "Epoch 006/041 | Loss 0.0071 | Win/lose count 11.5/18.700000000000003 (-7.200000000000003)\n",
            "Epoch 007/041 | Loss 0.0067 | Win/lose count 8.5/18.399999999999995 (-9.899999999999995)\n",
            "Epoch 008/041 | Loss 0.0383 | Win/lose count 13.0/16.799999999999976 (-3.799999999999976)\n",
            "Epoch 009/041 | Loss 0.0064 | Win/lose count 14.5/14.199999999999969 (0.3000000000000309)\n",
            "Epoch 010/041 | Loss 0.0061 | Win/lose count 10.5/16.29999999999996 (-5.799999999999962)\n",
            "Epoch 011/041 | Loss 0.0381 | Win/lose count 15.0/16.499999999999968 (-1.499999999999968)\n",
            "Epoch 012/041 | Loss 0.0062 | Win/lose count 16.0/16.99999999999997 (-0.9999999999999716)\n",
            "Epoch 013/041 | Loss 0.0304 | Win/lose count 20.0/14.299999999999972 (5.700000000000028)\n",
            "Epoch 014/041 | Loss 0.0350 | Win/lose count 22.0/13.199999999999969 (8.800000000000031)\n",
            "Epoch 015/041 | Loss 0.0094 | Win/lose count 12.5/14.499999999999964 (-1.9999999999999645)\n",
            "Epoch 016/041 | Loss 0.0095 | Win/lose count 26.0/13.099999999999975 (12.900000000000025)\n",
            "Epoch 017/041 | Loss 0.0475 | Win/lose count 22.0/12.899999999999977 (9.100000000000023)\n",
            "Epoch 018/041 | Loss 0.0090 | Win/lose count 26.5/9.599999999999982 (16.90000000000002)\n",
            "Epoch 019/041 | Loss 0.0084 | Win/lose count 23.5/11.699999999999978 (11.800000000000022)\n",
            "Epoch 020/041 | Loss 0.0260 | Win/lose count 20.0/13.499999999999973 (6.500000000000027)\n",
            "Epoch 021/041 | Loss 0.0058 | Win/lose count 19.5/15.899999999999974 (3.6000000000000263)\n",
            "Epoch 022/041 | Loss 0.0077 | Win/lose count 23.0/13.299999999999976 (9.700000000000024)\n",
            "Epoch 023/041 | Loss 0.0100 | Win/lose count 19.0/16.69999999999997 (2.300000000000029)\n",
            "Epoch 024/041 | Loss 0.0076 | Win/lose count 27.0/15.599999999999971 (11.400000000000029)\n",
            "Epoch 025/041 | Loss 0.0079 | Win/lose count 27.0/12.699999999999982 (14.300000000000018)\n",
            "Epoch 026/041 | Loss 0.0060 | Win/lose count 21.5/15.099999999999966 (6.400000000000034)\n",
            "Epoch 027/041 | Loss 0.0211 | Win/lose count 17.0/14.899999999999974 (2.1000000000000263)\n",
            "Epoch 028/041 | Loss 0.0077 | Win/lose count 23.5/12.69999999999997 (10.80000000000003)\n",
            "Epoch 029/041 | Loss 0.0259 | Win/lose count 18.0/15.399999999999968 (2.6000000000000316)\n",
            "Epoch 030/041 | Loss 0.0112 | Win/lose count 19.0/16.499999999999975 (2.500000000000025)\n",
            "Epoch 031/041 | Loss 0.0093 | Win/lose count 27.5/14.39999999999998 (13.10000000000002)\n",
            "Epoch 032/041 | Loss 0.0085 | Win/lose count 20.0/13.99999999999998 (6.0000000000000195)\n",
            "Epoch 033/041 | Loss 0.0101 | Win/lose count 22.5/14.099999999999978 (8.400000000000022)\n",
            "Epoch 034/041 | Loss 0.0216 | Win/lose count 25.0/11.799999999999978 (13.200000000000022)\n",
            "Epoch 035/041 | Loss 0.0067 | Win/lose count 20.0/12.599999999999971 (7.400000000000029)\n",
            "Epoch 036/041 | Loss 0.0137 | Win/lose count 23.5/15.89999999999997 (7.60000000000003)\n",
            "Epoch 037/041 | Loss 0.0153 | Win/lose count 22.5/12.29999999999998 (10.20000000000002)\n",
            "Epoch 038/041 | Loss 0.0054 | Win/lose count 24.5/16.899999999999984 (7.600000000000016)\n",
            "Epoch 039/041 | Loss 0.0282 | Win/lose count 27.0/12.399999999999983 (14.600000000000017)\n",
            "Epoch 040/041 | Loss 0.0144 | Win/lose count 20.0/13.499999999999973 (6.500000000000027)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvCukoLUF9ro",
        "colab_type": "code",
        "outputId": "c8fccc60-9e5f-4c6b-96b4-615d23f52e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 21.5/6.0. Average score (15.5)\n",
            "Win/lose count 17.0/0. Average score (16.25)\n",
            "Win/lose count 21.0/6.0. Average score (15.833333333333334)\n",
            "Win/lose count 17.5/2.0. Average score (15.75)\n",
            "Win/lose count 25.0/9.0. Average score (15.8)\n",
            "Win/lose count 26.0/6.0. Average score (16.5)\n",
            "Win/lose count 19.0/4.0. Average score (16.285714285714285)\n",
            "Win/lose count 14.0/3.0. Average score (15.625)\n",
            "Win/lose count 23.0/5.0. Average score (15.88888888888889)\n",
            "Win/lose count 16.0/2.0. Average score (15.7)\n",
            "Win/lose count 23.0/4.0. Average score (16.0)\n",
            "Final score: 16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJNdRv-nAuzF",
        "colab_type": "text"
      },
      "source": [
        "## Final results\n",
        "\n",
        "Parameters used:\n",
        "\n",
        "temperature of 0.3\n",
        "\n",
        "20 epochs for training DQN_FC and DQN_CNN (without encouraging exploration) \n",
        "\n",
        "40 epochs for training DQN_CNN_explore (encouraging exploration)\n",
        "\n",
        "10 epochs for the evaluation\n",
        "\n",
        "\n",
        "### Final score: \n",
        "\n",
        "DQN_FC: **4.37**\n",
        "\n",
        "DQN_CNN: **5.64**\n",
        "\n",
        "DQN_CNN_explore: **16**\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXfN4Q2F9rs",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2dsloQBF9rs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiNALSRZF9rt",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}